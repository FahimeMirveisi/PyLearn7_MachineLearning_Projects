{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "((1437, 64), (360, 64), (1437, 10), (360, 10))"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_digits()\n",
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "Y = np.eye(10)[Y]  #one hot\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "epochs = 80\n",
    "\n",
    "D_in = X_train.shape[1]\n",
    "H1 = 128\n",
    "H2 = 32\n",
    "D_out = Y_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, D_in, H1, H2, D_out, learning_rate=0.001):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.D_in = D_in\n",
    "        self.D_out = D_out\n",
    "        self.H1 = H1\n",
    "        self.H2 = H2\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(D_in, H1)\n",
    "        self.W2 = np.random.randn(H1, H2)\n",
    "        self.W3 = np.random.randn(H2, D_out)\n",
    "\n",
    "        self.B1 = np.random.randn(1, H1)\n",
    "        self.B2 = np.random.randn(1, H2)\n",
    "        self.B3 = np.random.randn(1, D_out)\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    def softmax(self, X):\n",
    "        return np.exp(X) / np.sum(np.exp(X))\n",
    "\n",
    "    def root_mean_square_error(self, Y_gt, Y_pred):\n",
    "        return np.sqrt(np.mean((Y_gt - Y_pred) ** 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #layer1\n",
    "        out1 = self.sigmoid(x.T @ self.W1 + self.B1)\n",
    "        #print('out1.shape:', out1.shape)\n",
    "\n",
    "        #layer2\n",
    "        out2 = self.sigmoid(out1 @ self.W2 + self.B2)\n",
    "        #print('out2.shape:', out2.shape)\n",
    "\n",
    "        #layer3\n",
    "        out3 = self.softmax(out2 @ self.W3 + self.B3)\n",
    "        #print('out3.shape:', out3.shape)\n",
    "\n",
    "        y_pred = out3\n",
    "        return out1, out2, y_pred\n",
    "\n",
    "    def backward(self,x ,y ,y_pred ,out1, out2):\n",
    "\n",
    "        #layer3\n",
    "        print('in backward y:', y)\n",
    "        print('in backward y shape is:', y.shape)\n",
    "        print('in backward y_pred:', y_pred)\n",
    "        print('in backward y_pred shape is:', y_pred.shape)\n",
    "        error = -2 * (y - y_pred) # error dar vaghe hamman grad_error yani moshtagh error hast\n",
    "        grad_B3 = error\n",
    "        grad_W3 = out2.T @ error\n",
    "\n",
    "        #layer2\n",
    "        error = error @ self.W3.T * out2 * (1 - out2)\n",
    "        grad_B2 = error\n",
    "        grad_W2 = out1.T @ error\n",
    "\n",
    "        #layer1\n",
    "        error = error @ self.W2.T * out1 * (1 - out1)\n",
    "        grad_B1 = error\n",
    "        grad_W1 = x @ error\n",
    "\n",
    "        self.update(grad_W1, grad_B1, grad_W2, grad_B2, grad_W3, grad_B3)\n",
    "\n",
    "\n",
    "    def update(self, grad_W1, grad_B1, grad_W2, grad_B2, grad_W3, grad_B3):\n",
    "        #update\n",
    "\n",
    "        #layer1\n",
    "        self.W1 -= self.learning_rate * grad_W1\n",
    "        self.B1 -= self.learning_rate * grad_B1\n",
    "\n",
    "        #layer2\n",
    "        self.W2 -= self.learning_rate * grad_W2\n",
    "        self.B2 -= self.learning_rate * grad_B2\n",
    "\n",
    "        #layer3\n",
    "        self.W3 -= self.learning_rate * grad_W3\n",
    "        self.B3 -= self.learning_rate * grad_B3\n",
    "\n",
    "    #train\n",
    "    def train_test(self, epochs, X_train, Y_train, X_test, Y_test):\n",
    "        for epoch in range(epochs):\n",
    "            Y_pred_train = []\n",
    "            for x,y in zip(X_train, Y_train):\n",
    "\n",
    "                x = x.reshape(-1, 1)\n",
    "                print('x.shape:',x.shape)\n",
    "                print('y.shape:', y.shape)\n",
    "\n",
    "                #forward\n",
    "\n",
    "                out1, out2, y_pred = self.forward(x)\n",
    "                Y_pred_train.append(y_pred)\n",
    "\n",
    "                #backward\n",
    "                print('y_pred.shape:', y.shape)\n",
    "                self.backward(x ,y ,y_pred ,out1, out2)\n",
    "\n",
    "\n",
    "            Y_pred_test = []\n",
    "            for x,y in zip(X_test, Y_test):\n",
    "\n",
    "                x = x.reshape(-1, 1)\n",
    "                print('x_test:',x,'x.shape:',x.shape)\n",
    "                print('y_test:',y,'y.shape:', y.shape)\n",
    "                #forward\n",
    "\n",
    "                out1, out2, y_pred = self.forward(x)\n",
    "                Y_pred_test.append(y_pred)\n",
    "\n",
    "\n",
    "        Y_pred_train = np.array(Y_pred_train).reshape(-1, 10)\n",
    "\n",
    "        loss_train = self.root_mean_square_error(Y_train, Y_pred_train)\n",
    "        accuracy_train = np.sum(np.argmax(Y_train, axis=1) == np.argmax(Y_pred_train, axis=1)) / len(Y_train)\n",
    "        print('----------------------------epoch:', epoch,'--------------------------------------------')\n",
    "        print('loss train:',loss_train)\n",
    "        print('accuracy train:',accuracy_train)\n",
    "\n",
    "        Y_pred_test = np.array(Y_pred_test).reshape(-1, 10)\n",
    "\n",
    "        loss_test = self.root_mean_square_error(Y_test, Y_pred_test)\n",
    "        accuracy_test = np.sum(np.argmax(Y_test, axis=1) == np.argmax(Y_pred_test, axis=1)) / len(Y_test)\n",
    "\n",
    "        print('loss test:',loss_test)\n",
    "        print('accuracy test:',accuracy_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (64, 1)\n",
      "y.shape: (10,)\n",
      "y_pred.shape: (10,)\n",
      "in backward y: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "in backward y shape is: (10,)\n",
      "in backward y_pred: [[2.23364417e-01 2.50486776e-06 1.08869942e-08 3.03373099e-03\n",
      "  3.53124547e-06 1.04154055e-03 1.84693079e-04 1.41609597e-06\n",
      "  6.23977818e-06 5.06033848e-05 2.82705062e-05 1.58591445e-04\n",
      "  4.19522843e-04 4.53084378e-06 1.79986138e-07 4.98992029e-04\n",
      "  6.26251476e-10 5.90832173e-04 1.85351944e-05 8.11569257e-03\n",
      "  1.41729675e-04 2.80616869e-03 3.43302763e-07 2.61498567e-06\n",
      "  1.93801109e-06 4.14162014e-04 1.38284184e-05 2.62685957e-04\n",
      "  1.25038090e-07 1.47011551e-06 2.06915034e-04 1.06579759e-07\n",
      "  2.89540065e-01 1.40952697e-02 5.29165584e-05 3.10409689e-06\n",
      "  6.26321374e-09 2.15701143e-04 6.60385392e-06 5.41884218e-05\n",
      "  5.81479026e-09 2.81944865e-04 3.99580933e-05 2.29008038e-05\n",
      "  9.75609969e-09 2.72822175e-01 6.30781228e-03 5.23358898e-05\n",
      "  1.99650075e-05 2.52431387e-06 4.64777456e-07 1.05068360e-03\n",
      "  3.97090967e-08 2.63563222e-03 2.77059987e-05 2.09673130e-07\n",
      "  2.28048478e-07 8.27338756e-04 2.45303985e-07 1.58314253e-01\n",
      "  1.22072306e-02 6.62333577e-08 3.02973632e-05 1.21950098e-05]]\n",
      "in backward y_pred shape is: (1, 64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (1,64) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m mlp_model \u001B[38;5;241m=\u001B[39m MLP(D_in\u001B[38;5;241m=\u001B[39mX_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], H1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, H2\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, D_out\u001B[38;5;241m=\u001B[39mX_test\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmlp_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m80\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[28], line 99\u001B[0m, in \u001B[0;36mMLP.train_test\u001B[1;34m(self, epochs, X_train, Y_train, X_test, Y_test)\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;66;03m#backward\u001B[39;00m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_pred.shape:\u001B[39m\u001B[38;5;124m'\u001B[39m, y\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m---> 99\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43mout1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    102\u001B[0m Y_pred_test \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x,y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(X_test, Y_test):\n",
      "Cell \u001B[1;32mIn[28], line 50\u001B[0m, in \u001B[0;36mMLP.backward\u001B[1;34m(self, x, y, y_pred, out1, out2)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124min backward y_pred:\u001B[39m\u001B[38;5;124m'\u001B[39m, y_pred)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124min backward y_pred shape is:\u001B[39m\u001B[38;5;124m'\u001B[39m, y_pred\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m---> 50\u001B[0m error \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m) \u001B[38;5;66;03m# error dar vaghe hamman grad_error yani moshtagh error hast\u001B[39;00m\n\u001B[0;32m     51\u001B[0m grad_B3 \u001B[38;5;241m=\u001B[39m error\n\u001B[0;32m     52\u001B[0m grad_W3 \u001B[38;5;241m=\u001B[39m out2\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m error\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (10,) (1,64) "
     ]
    }
   ],
   "source": [
    "mlp_model = MLP(D_in=X_train.shape[1], H1=128, H2=32, D_out=X_test.shape[1])\n",
    "mlp_model.train_test(epochs=80, X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"num2.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image = image.reshape(64, 1)\n",
    "\n",
    "x = image\n",
    "#forward\n",
    "\n",
    "#layer1\n",
    "out1 = mlp_model.sigmoid(x.T @ mlp_model.W1 + mlp_model.B1)\n",
    "\n",
    "#layer2\n",
    "out2 = mlp_model.sigmoid(out1 @ mlp_model.W2 + mlp_model.B2)\n",
    "\n",
    "#layer3\n",
    "out3 = mlp_model.softmax(out2 @ mlp_model.W3 + mlp_model.B3)\n",
    "y_pred = out3\n",
    "print(np.argmax(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}